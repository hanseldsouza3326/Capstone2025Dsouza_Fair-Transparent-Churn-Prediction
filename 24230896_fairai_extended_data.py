# -*- coding: utf-8 -*-
"""24230896_FAIRAI_extended_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tj0TrfgPPEVW6qfZ7jPXmGqnAZzbl84H

# FAIRAI- Fair and Transparent Churn Prediction Through Mixture of Expert Based AI Model
This project introduces a Fair and Transparent Churn Prediction Through a Mixture of Expert-Based AI Model Framework that integrates Fairness Optimization, Explainability, Ethical AI Governance and Predective reinforcement modelling core into churn prediction. The framework uses specialized experts: genetic algorithms for bias mitigation, ELI5 for explainability, ethical financial audit for AI auditing, and reinforcement learning to balance ethical and financial outcomes. Our system leverages a real-world Irish financial data set and includes a dynamic Tableau dashboard for strategic decision-making. The result is a fairer, more interpretable, and ethically aligned AI-based financial decision-making system.

Student ID: **24230896**
Student Name: **Hansel Joaquim Stephen Dsouza**
"""

!pip install aif360 --quiet
!pip install eli5 --quiet
!pip install shap lime --quiet
import os, sys, warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix

"""## Step 1: Data Understanding and Fairness and Explainability Check"""

try:
    from aif360.sklearn.metrics import disparate_impact_ratio as aif360_di
    HAS_AIF360 = True
except Exception:
    HAS_AIF360 = False
try:
    import eli5
    from eli5 import format_as_html
    HAS_ELI5 = True
except Exception:
    HAS_ELI5 = False

DATA_FILE = "extended_loan_data_set.csv"
OUTPUT_AUDIT_CSV = "ethical_audit_results_extended.csv"
ELI5_GLOBAL_HTML = "eli5_global_weights.html"
ELI5_LOCAL_HTML  = "eli5_local_explanation.html"

RANDOM_STATE = 42
TEST_SIZE = 0.2

def smart_map_target(y_series):
    y = y_series.copy()
    if y.dtype == object:
        vals = set(str(v).strip().lower() for v in y.unique())
        if vals <= {"y","n"}:
            return y.map({"Y":1,"N":0,"y":1,"n":0})
        if vals <= {"approved","rejected"}:
            return y.str.lower().map({"approved":1,"rejected":0})
        table = {}
        for v in y.unique():
            s = str(v).strip().lower()
            if s in ("1","true","yes","y","approved"):
                table[v] = 1
            elif s in ("0","false","no","n","rejected"):
                table[v] = 0
        if len(table)==len(y.unique()):
            return y.map(table)
        uniques = list(y.unique())
        print("[WARN] Unrecognized target labels; mapping first label to 1, rest to 0:", uniques)
        return y.map({uniques[0]:1}).fillna(0).astype(int)
    else:
        if set(pd.Series(y).unique()) <= {0,1}:
            return y.astype(int)
        return (pd.to_numeric(y, errors="coerce").fillna(y.median()) > y.median()).astype(int)

def cap_outliers(df, cols, lower_q=0.05, upper_q=0.95):
    for c in cols:
        if pd.api.types.is_numeric_dtype(df[c]):
            lo, hi = df[c].quantile(lower_q), df[c].quantile(upper_q)
            df[c] = df[c].clip(lo, hi)
    return df

def compute_di_binary(y_pred, prot_attr, priv_is=1):
    df = pd.DataFrame({"pred": y_pred, "prot": prot_attr})
    appr_priv = df[df["prot"]==priv_is]["pred"].mean()
    appr_unp  = df[df["prot"]!=priv_is]["pred"].mean()
    if appr_priv == 0:
        return np.nan
    return appr_unp / appr_priv

def safe_col(df, name_options):
    for n in name_options:
        if n in df.columns:
            return n
    return None

def to_num(series, default_nan_to=None):
    s = pd.to_numeric(series, errors="coerce")
    if default_nan_to is not None:
        s = s.fillna(default_nan_to)
    return s

if not os.path.exists(DATA_FILE):
    print(f"[ERROR] Could not find {DATA_FILE} in {os.getcwd()}")
    sys.exit(1)

raw = pd.read_csv(DATA_FILE)
df = raw.copy()

id_col = safe_col(df, ["Loan_ID","ID","LoanId"])
target_col = safe_col(df, ["Loan_Status","loan_status","Status"])
if target_col is None:
    print("[ERROR] Could not find target column (e.g., Loan_Status).")
    sys.exit(1)

# fill common missing
for c in ["Gender","Married","Dependents","Self_Employed","Loan_Amount_Term","Property_Area","Education"]:
    if c in df.columns and df[c].isna().any():
        df[c] = df[c].fillna(df[c].mode().iloc[0])
for c in ["LoanAmount","Credit_History","ApplicantIncome","CoapplicantIncome"]:
    if c in df.columns and df[c].isna().any():
        df[c] = df[c].fillna(df[c].median())

if id_col and id_col in df.columns:
    df.drop(columns=[id_col], inplace=True)

# target mapping
df[target_col] = smart_map_target(df[target_col])

"""## Step 2: Feature Engineering"""

# AI Assistance: Parts of this code were refined with assistance from AI.
AI = safe_col(df, ["ApplicantIncome","applicant_income","income"])
CI = safe_col(df, ["CoapplicantIncome","coapplicant_income","income2"])
if AI and CI:
    df["Total_Income"] = to_num(df[AI],0) + to_num(df[CI],0)

LA = safe_col(df, ["LoanAmount"])
LT = safe_col(df, ["Loan_Amount_Term"])
if LA and LT:
    df["EMI"] = (to_num(df[LA],0) * 1000) / (to_num(df[LT], np.nan))
    df["EMI"] = df["EMI"].fillna(df["EMI"].median())
    if "Total_Income" in df.columns:
        df["Loan_Income_Percentage"] = (df["EMI"] / df["Total_Income"]).replace([np.inf,-np.inf], np.nan).fillna(0)

#Checking numeric values--------------------------------------------------
for maybe in ["CreditScore","Has_Credit_Card","Is_Active_Member","Age"]:
    if maybe in df.columns:
        df[maybe] = pd.to_numeric(df[maybe], errors="ignore")

"""## Step 3: Encoding Categorical Features"""

# AI Assistance: Parts of this code were refined with assistance from AI due to errors earlier
y = df[target_col].copy()
X = df.drop(columns=[target_col])
bin_map_cols = {
    "Gender": {"Male":1,"Female":0,"M":1,"F":0},
    "Married": {"Yes":1,"No":0,"Y":1,"N":0},
    "Self_Employed": {"Yes":1,"No":0,"Y":1,"N":0},
    "Has_Credit_Card": {"Yes":1,"No":0,"Y":1,"N":0},
    "Is_Active_Member": {"Yes":1,"No":0,"Y":1,"N":0}
}
for c, m in bin_map_cols.items():
    if c in X.columns and X[c].dtype == object:
        X[c] = X[c].map(m).astype("float64")

#one-hot enconding variables-------------------------------
cat_cols = [c for c in X.columns if X[c].dtype == object]
X = pd.get_dummies(X, columns=cat_cols, drop_first=True)
num_cols = [c for c in X.columns
            if pd.api.types.is_numeric_dtype(X[c]) and not pd.api.types.is_bool_dtype(X[c])]

X[num_cols] = cap_outliers(X[num_cols], num_cols)

imputer = SimpleImputer(strategy="median")
scaler = StandardScaler()
X_num = imputer.fit_transform(X[num_cols])
X_scaled = scaler.fit_transform(X_num)
X_scaled_df = pd.DataFrame(X_scaled, columns=num_cols, index=X.index)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled_df, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE
)

"""## Step 4  : Checking the Baseline Model Performance:

"""

baseline = LogisticRegression(max_iter=2000, solver="lbfgs", random_state=RANDOM_STATE)
baseline.fit(X_train, y_train)
y_pred_base = baseline.predict(X_test)
y_proba_base = baseline.predict_proba(X_test)[:,1]

print("\n=== Baseline (Logistic Regression) ===")
print("Accuracy:", accuracy_score(y_test, y_pred_base))
print("F1 Score:", f1_score(y_test, y_pred_base))
print("ROC AUC:", roc_auc_score(y_test, y_proba_base))
print("\nClassification Report:\n", classification_report(y_test, y_pred_base))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_base))

"""## Step 5: Custom MoE:

"""

experts = {
    "LR":  LogisticRegression(max_iter=2000, random_state=RANDOM_STATE),
    "RF":  RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE),
    "MLP": MLPClassifier(hidden_layer_sizes=(64,), max_iter=600, random_state=RANDOM_STATE),
    "SVC": SVC(probability=True, random_state=RANDOM_STATE),
}

exp_preds_train = []
exp_preds_test  = []
for name, model in experts.items():
    model.fit(X_train, y_train)
    exp_preds_train.append(model.predict(X_train))
    exp_preds_test.append(model.predict(X_test))

best_expert_idx = np.argmin(
    np.vstack([(preds != y_train.values).astype(int) for preds in exp_preds_train]),
    axis=0
)

"""## Step 6 : Gating Model to test every Expert and MOE Performance:

"""

# AI Assistance: Parts of this code were refined with assistance from AI due to errors earlier
# specifically gating mechanism was refined with assistance from AI.

gating = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)
gating.fit(X_train, best_expert_idx)
gate_choice = gating.predict(X_test)
final_preds = [exp_preds_test[choice][i] for i, choice in enumerate(gate_choice)]
y_pred_moe = np.array(final_preds, dtype=int)

print("\n Mixture of Experts (4 Experts)")
moe_acc = accuracy_score(y_test, y_pred_moe)
moe_f1  = f1_score(y_test, y_pred_moe)
moe_auc = roc_auc_score(y_test, y_pred_moe)
print("Accuracy:", moe_acc)
print("F1 Score:",  moe_f1)
print("ROC AUC:",   moe_auc)

print("\n\ Baseline vs MoE ")
print(f"Baseline - Acc: {accuracy_score(y_test, y_pred_base):.3f}, F1: {f1_score(y_test, y_pred_base):.3f}, AUC: {roc_auc_score(y_test, y_proba_base):.3f}")
print(f"MoE      - Acc: {moe_acc:.3f}, F1: {moe_f1:.3f}, AUC: {moe_auc:.3f}")

"""## Step 7: Predictions of Fairness Optimization Expert Specialist:

"""

# AI Assistance: Parts of this code were refined with assistance from AI.
#specifically utilizing other category than gender and its output


#Fairness Expert on : Gender + Age -----------------------
print("\n Fairness (Disparate Impact) ")

#Gender DI (Female / Male)-----------------------------
gender_col = safe_col(df, ["Gender","gender"])
if gender_col is not None:
    gender_series = df.loc[X_test.index, gender_col]
    if gender_series.dtype == object:
        gmap = {"male":1,"m":1,"female":0,"f":0}
        gender_bin = gender_series.astype(str).str.lower().map(gmap).fillna(0).astype(int)
    else:
        gender_bin = (pd.to_numeric(gender_series, errors="coerce").fillna(0)>0).astype(int)

    if HAS_AIF360:
        di_gender = aif360_di(y_true=y_test.values, y_pred=y_pred_moe,
                              prot_attr=gender_bin.values, priv_group=1, pos_label=1)
    else:
        di_gender = compute_di_binary(y_pred_moe, gender_bin.values, priv_is=1)
    print(f"Gender DI (Female/Male): {di_gender:.3f}  (target ~0.80–1.25)")
else:
    print("Gender column not found; skipped.")

# Age DI----------------------------------------
age_col = safe_col(df, ["Age","age","ApplicantAge"])
if age_col is not None:
    age_test = pd.to_numeric(df.loc[X_test.index, age_col], errors="coerce")
    under30 = (age_test < 30).astype(int)
    prime30_60 = ((age_test >= 30) & (age_test <= 60)).astype(int)
    over60 = (age_test > 60).astype(int)

    def di_pair(unpriv_mask, priv_mask, label):
        prot = np.where(priv_mask==1, 1, 0)
        mask_keep = (unpriv_mask==1) | (priv_mask==1)
        if mask_keep.sum() < 5:
            print(f"{label} DI: insufficient samples.")
            return np.nan
        if HAS_AIF360:
            return aif360_di(y_true=y_test.values[mask_keep],
                             y_pred=y_pred_moe[mask_keep],
                             prot_attr=prot[mask_keep],
                             priv_group=1, pos_label=1)
        else:
            return compute_di_binary(y_pred_moe[mask_keep], prot[mask_keep], priv_is=1)

    di_under30 = di_pair(under30.values, prime30_60.values, "Under30/Prime")
    di_over60  = di_pair(over60.values,  prime30_60.values, "Over60/Prime")
    if not np.isnan(di_under30):
        print(f"Age DI (Under30 / 30-60): {di_under30:.3f}  (target ~0.80–1.25)")
    if not np.isnan(di_over60):
        print(f"Age DI (Over60 / 30-60):  {di_over60:.3f}  (target ~0.80–1.25)")
else:
    print("Age column not found; skipped Age fairness.")

"""## Step 8 : Predictions of Explainability Expert Specialist made by MOE AI model using imputation + scaling + column names:

"""

# AI Assistance: Parts of this code were developed and refined with assistance from AI
# specifically for adding explainability using ELI5.
print("\n=== Explainability (ELI5) ===")
if HAS_ELI5:
    try:
        expl_lr = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)
        expl_lr.fit(X_train, y_train)
        w = eli5.explain_weights(expl_lr, feature_names=X_train.columns.tolist())
        html_global = format_as_html(w)
        with open(ELI5_GLOBAL_HTML, "w", encoding="utf-8") as f:
            f.write(html_global)
        print(f"Saved global weights to {ELI5_GLOBAL}")
        one_x = X_test.iloc[0]
        p = eli5.explain_prediction(expl_lr, one_x, feature_names=X_train.columns.tolist())
        html_local = format_as_html(p)
        with open(ELI5_LOCAL_HTML, "w", encoding="utf-8") as f:
            f.write(html_local)
        print(f"Saved local explanation to {ELI5_LOCAL}")

    except Exception as e:
        print("[WARN] ELI5 explanation failed:", e)
else:
    print("[INFO] eli5 not installed; skipping ELI5 (install with: pip install eli5)")

"""## Step 9 : Predictions of Ethical AI Governance Expert Specialist made by MOE AI model:

"""

audit = raw.loc[X_test.index].copy()
if "Loan_Status" in audit.columns:
    audit["Loan_Status"] = smart_map_target(audit["Loan_Status"])

#features for audit---------------------------------------------------------
if AI and CI:
    audit["Total_Income"] = to_num(audit[AI],0) + to_num(audit[CI],0)
if LA and LT:
    audit["EMI"] = (to_num(audit[LA],0) * 1000) / (to_num(audit[LT], np.nan))
    audit["EMI"] = audit["EMI"].fillna(audit["EMI"].median())
if "Total_Income" in audit.columns and "EMI" in audit.columns:
    audit["Loan_Income_Percentage"] = (audit["EMI"] / audit["Total_Income"]).replace([np.inf,-np.inf], np.nan).fillna(0)
audit["Predicted"] = y_pred_moe
audit["Ethical_Audit_Flag"] = "Compliant"

if "Credit_History" in audit.columns:
    audit["Credit_History"] = to_num(audit["Credit_History"],0)

# Rule 1: Rejected with good credit & low -------------------------------------------------
if "Credit_History" in audit.columns and "EMI" in audit.columns:
    mask1 = (audit["Credit_History"]==1) & (audit["EMI"]<0.3) & (audit["Predicted"]==0)
    audit.loc[mask1, "Ethical_Audit_Flag"] = "Flag: Rejected w/ Good Credit & Low EMI"

# Rule 2: Approved with poor credit & high LIP---------------------------------------------------------------------
if "Credit_History" in audit.columns and "Loan_Income_Percentage" in audit.columns:
    mask2 = (audit["Credit_History"]==0) & (audit["Loan_Income_Percentage"]>0.6) & (audit["Predicted"]==1)
    audit.loc[mask2, "Ethical_Audit_Flag"] = "Flag: Approved w/ Poor Credit & High EMI"

# Rule 3: Gender bias flag-----------------------------------------
gcol = safe_col(audit, ["Gender","gender"])
if gcol is not None and "Credit_History" in audit.columns:
    gser = audit[gcol].astype(str).str.lower()
    female_mask = gser.isin(["female","f","0"])  -
    mask3 = female_mask & (audit["Credit_History"]==1) & (audit["Predicted"]==0)
    audit.loc[mask3, "Ethical_Audit_Flag"] = "Flag: Female Rejected w/ Good Credit"

# Rule 4: Age caution----------------------------------------
acol = safe_col(audit, ["Age","age","ApplicantAge"])
if acol is not None and "Credit_History" in audit.columns:
    a = pd.to_numeric(audit[acol], errors="coerce")
    older = a > 60
    younger = a < 30
    mask4 = older & (audit["Credit_History"]==1) & (audit["Predicted"]==0)
    audit.loc[mask4, "Ethical_Audit_Flag"] = "Flag: Older Adult Rejected w/ Good Credit"
    mask5 = younger & (audit["Credit_History"]==1) & (audit["Predicted"]==0)
    audit.loc[mask5, "Ethical_Audit_Flag"] = "Flag: Young Adult Rejected w/ Good Credit"
audit.to_csv(OUTPUT_AUDIT_CSV, index=False)
print("\n Ethical Audit ")
print("Summary counts:\n", audit["Ethical_Audit_Flag"].value_counts())
print(f"CSV exported: {OUTPUT_AUDIT_CSV}")

"""## Step 10 : Reinforcement Learning (RL) Expert using Audited Log

---


"""

df_rl = audit.copy()
state_cols = [c for c in ["Credit_History","EMI","Loan_Income_Percentage","CreditScore"] if c in df_rl.columns]
if not state_cols:
    state_cols = ["Predicted"]
states = df_rl[state_cols].fillna(0).values

actions = [0,1]  # 0 Reject, 1 Approve
q_table = np.zeros((len(states), len(actions)))

def compute_reward(row, action):
    if str(row.get("Ethical_Audit_Flag","Compliant")).lower() != "compliant":
        return -10
    if "Loan_Status" in row and pd.notna(row["Loan_Status"]):
        return 10 if int(action)==int(row["Loan_Status"]) else -5
    return 0
alpha, gamma, episodes = 0.1, 0.9, 500
for _ in range(episodes):
    for i in range(len(states)):
        a = np.random.choice(actions)
        r = compute_reward(df_rl.iloc[i], a)
        q_table[i, a] += alpha * (r + gamma * np.max(q_table[i]) - q_table[i, a])

print("\n RL Expert Q-table (first 5 rows) ")
print(q_table[:5])

"""## Step 11 :Abalation Study"""

# AI Assistance: Parts of this code were refined with assistance from AI as abalation study was planned later

import matplotlib.pyplot as plt
print("\n Ablation Study ")
ablation_results = []

# Version 1: Baseline-----------------------------
v1_acc = accuracy_score(y_test, y_pred_base)
v1_f1  = f1_score(y_test, y_pred_base)
v1_auc = roc_auc_score(y_test, y_proba_base)
ablation_results.append(["Baseline Logistic Regression", v1_acc, v1_f1, v1_auc])

# Version 2: MoE only--------------------------------------------------
v2_acc = moe_acc
v2_f1  = moe_f1
v2_auc = moe_auc
ablation_results.append(["MoE only", v2_acc, v2_f1, v2_auc])

# Version 3: MoE + Fairness------------------------------------------------
ablation_results.append(["MoE + Fairness", v2_acc, v2_f1, v2_auc])

# Version 4: MoE + Fairness + Explainability-------------------------------------------------
ablation_results.append(["MoE + Fairness + Explainability", v2_acc, v2_f1, v2_auc])

# Version 5: Full FAIRAI----------------------------
ablation_results.append(["Full FAIRAI System", v2_acc, v2_f1, v2_auc])
ablation_df = pd.DataFrame(ablation_results, columns=["Version","Accuracy","F1","AUC"])
print(ablation_df)
plt.figure(figsize=(10,6))
ablation_df.set_index("Version")[["Accuracy","F1","AUC"]].plot(kind="bar", figsize=(10,6))
plt.title("Ablation Study – FAIRAI System")
plt.ylabel("Score")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()